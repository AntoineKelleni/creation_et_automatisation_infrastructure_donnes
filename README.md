#  Cr√©er et automatiser une infrastructure de donn√©es

##  Contexte du projet

Dans le cadre de ce projet, l‚Äôobjectif est de concevoir et automatiser une **infrastructure de donn√©es moderne** permettant d‚Äôanalyser les pratiques sportives des employ√©s d‚Äôune entreprise, afin de calculer des **avantages sociaux li√©s au sport** (primes sportives, jours wellness, indicateurs RH)..

Le projet est r√©alis√© sous forme de **POC (Proof of Concept)**, avec une architecture automatis√©e, reproductible et monitor√©e, conforme aux bonnes pratiques Data Engineer.

---
<p align="center">
  <img src="docs/images/Diagramme.png" alt="rapport PowerBI dashboard" width="1400">
  <br>
  <em>Vue d‚Äôensemble du pipeline ETL orchestr√© avec Apache Airflow</em>
</p>

## P√©rim√®tre fonctionnel du POC

Le p√©rim√®tre du projet couvre les axes suivants :

1. **Ingestion de donn√©es multi-sources (Excel)**
2. **Nettoyage et normalisation des donn√©es**
3. **G√©n√©ration de donn√©es sportives simul√©es (type API Strava)**
4. **Contr√¥les de qualit√© de donn√©es et r√®gles m√©tier bloquantes**
5. **Calculs m√©tiers et agr√©gation analytique**
6. **Restitution des r√©sultats via Power BI**

---

##  Architecture technique
###  Composants principaux, stack utilis√©e

- **Docker / Docker Compose** : orchestration des services
- **PostgreSQL** : base de donn√©es relationnelle
- **Apache Airflow** : orchestration des pipelines de donn√©es
- **Python** : ingestion, transformations, contr√¥les qualit√©
- **SQL** : transformations, r√®gles m√©tier et et calculs analytiques
- **Power BI** : visualisation et reporting

---

## üóÑÔ∏è Mod√©lisation des donn√©es

### Sch√©mas PostgreSQL

- `raw` : donn√©es brutes (ingestion)
- `clean` : donn√©es nettoy√©es et normalis√©es
- `analytics` : tables pr√™tes pour la BI
- `meta` : param√®tres m√©tiers et suivi d‚Äôex√©cution

### Exemples de tables cl√©s

- `raw.commute_distance_checks`
- `clean.employees`
- `clean.activities`
- `analytics.employee_benefits`

---

##  Pipelines de donn√©es (ETL)

Les pipelines sont orchestr√©s par **Apache Airflow**.

### DAG `poc_01_ingest_and_clean`

- Ingestion des fichiers Excel RH et Sport
- Chargement dans la couche `raw`
- Nettoyage et normalisation vers la couche `clean`
- Pipeline **idempotent** et rejouable

### DAG `poc_02_generate_activities`

- G√©n√©ration automatique d‚Äôactivit√©s sportives
- Simulation d‚Äôune API de type Strava
- Alimentation de la table `clean.activities`

### DAG `poc_05_quality_checks`

- Ex√©cution de contr√¥les qualit√© bloquants
- V√©rification des r√®gles de coh√©rence et m√©tier
- Arr√™t du pipeline en cas d‚Äôanomalie critique

---

##  Tests de qualit√© des donn√©es

###  Tests de coh√©rence
- Valeurs non nulles sur les champs critiques
- Unicit√© des identifiants (`employee_id`, `activity_id`)
- Valeurs positives (distances, dur√©es, salaires)
- Validit√© des dates (`end_ts >= start_ts`)

### üìê Tests de r√®gles m√©tier

R√®gle de coh√©rence domicile‚Äìtravail selon le mode de transport :

| Mode de transport           | Distance maximale autoris√©e |
|-----------------------------|-----------------------------|
| Marche / Running            | ‚â§ 15 km                     |
| V√©lo / Trottinette / Autres | ‚â§ 25 km                     |

Toute distance d√©passant ces seuils est consid√©r√©e comme **anormale**.

---

##  D√©monstration des tests (FAIL ‚Üí PASS)

Afin de d√©montrer le bon fonctionnement des r√®gles m√©tier :

1. **Injection de donn√©es mock√©es** (distances incoh√©rentes)
2. Ex√©cution du DAG `poc_05_quality_checks` ‚Üí **FAIL**
3. Correction des donn√©es mock√©es
4. Nouvelle ex√©cution du DAG ‚Üí **PASS**

Scripts SQL utilis√©s :
- `src/db/mock_commute_distance_fail.sql`
- `src/db/mock_commute_distance_fix.sql`

Cette approche permet de d√©montrer :
- la d√©tection automatique des anomalies
- la tra√ßabilit√© des erreurs
- la robustesse du pipeline

---

##  Monitoring du pipeline

Le monitoring est assur√© par :

- **Airflow UI** :
  - statut des DAGs (SUCCESS / FAILED)
  - logs d√©taill√©s par t√¢che
- **Contr√¥les de volum√©trie** :
  - seuil minimal de lignes attendu
  - d√©tection de ruptures de flux
- **Logs SQL et Python** :
  - remont√©e des anomalies m√©tier

---

##  Restitution des r√©sultats (Power BI)
<p align="center">
  <img src="docs/images/rapport_powerBI.png" alt="rapport PowerBI dashboard" width="900">
  <br>
  <em>Vue d‚Äôensemble du dashboard PowerBI</em>
</p>
Les donn√©es consolid√©es dans le sch√©ma `analytics` permettent de visualiser :

- Nombre de jours suppl√©mentaires attribu√©s
- R√©partition des pratiques sportives
- Co√ªts estim√©s des avantages
- Volum√©trie d‚Äôactivit√©s par p√©riode
- D√©tection des anomalies de d√©claration

Power BI est utilis√© comme outil de restitution final.

---

##  Choix techniques et bonnes pratiques

- Architecture modulaire et extensible
- Pipelines idempotents
- S√©paration claire des couches de donn√©es
- Tests qualit√© automatis√©s et bloquants
- Tol√©rance aux sources absentes (POC)
- Documentation claire et reproductibilit√©

---

## Conclusion

Ce projet d√©montre la capacit√© √† :
- concevoir une infrastructure de donn√©es compl√®te
- automatiser des flux ETL fiables
- impl√©menter des r√®gles m√©tier robustes
- monitorer et s√©curiser la qualit√© des donn√©es
- produire des indicateurs exploitables pour la prise de d√©cision

Il constitue une base solide pour une mise en production future.

